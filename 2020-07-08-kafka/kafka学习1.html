<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="悟空的技术博客"><title>Kafka学习(一) | 悟空</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka学习(一)</h1><a id="logo" href="/.">悟空</a><p class="description">悟空的技术博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tag"> 标签</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kafka学习(一)</h1><div class="post-meta">Jul 8, 2020<span> | </span><span class="category"><a href="/categories/kafka/">kafka</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-什么是-kafka？"><span class="toc-text">1. 什么是 kafka？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Kafka-amp-MQ-场景"><span class="toc-text">1.1 Kafka & MQ 场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Kafka-架构刨析"><span class="toc-text">1.2 Kafka 架构刨析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#常见消息队列模式"><span class="toc-text">常见消息队列模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Record、Topic、Broker、Leader-、-Fllower-和分区"><span class="toc-text">Record、Topic、Broker、Leader 、 Fllower 和分区</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-kafka-特性"><span class="toc-text">1.3 kafka 特性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#顺序写-amp-mmap-针对生产者"><span class="toc-text">顺序写&mmap-针对生产者</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Zero-Copy-针对消费者"><span class="toc-text">Zero Copy-针对消费者</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-安装-amp-部署"><span class="toc-text">2. 安装&部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-单机-集群环境搭建"><span class="toc-text">2.1 单机/集群环境搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-kafka-集群环境搭建"><span class="toc-text">2.2 kafka 集群环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#集群配置"><span class="toc-text">集群配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用集群"><span class="toc-text">使用集群</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Kafka-基础-API"><span class="toc-text">3. Kafka 基础 API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-topic-的基本操作"><span class="toc-text">3.1 topic 的基本操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-生产者-消费者代码"><span class="toc-text">3.2 生产者/消费者代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-自定义分区策略"><span class="toc-text">3.4 自定义分区策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#默认分区策略"><span class="toc-text">默认分区策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#自定义分区策略"><span class="toc-text">自定义分区策略</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-消息的序列化"><span class="toc-text">3.3 消息的序列化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Kafka-API-高级特性"><span class="toc-text">4. Kafka API 高级特性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-消息拦截器"><span class="toc-text">4.1 消息拦截器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Offset-偏移量控制"><span class="toc-text">4.2 Offset 偏移量控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Acks-amp-Retries"><span class="toc-text">4.3 Acks & Retries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-幂等性"><span class="toc-text">4.3 幂等性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-事务控制"><span class="toc-text">4.4 事务控制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#生产者-only"><span class="toc-text">生产者 only</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#生产者消费者事务"><span class="toc-text">生产者消费者事务</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Kafka-架构进阶"><span class="toc-text">5. Kafka 架构进阶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Kafka-副本同步机制"><span class="toc-text">5.1 Kafka 副本同步机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#关键概念理解"><span class="toc-text">关键概念理解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#follower-副本更新-LEO-时机"><span class="toc-text">follower 副本更新 LEO 时机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#follower-副本更新-HW-时机"><span class="toc-text">follower 副本更新 HW 时机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#leader-副本更新-LEO-时机"><span class="toc-text">leader 副本更新 LEO 时机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#leader-副本更新-HW-时机"><span class="toc-text">leader 副本更新 HW 时机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#例子：一个-topic，单分区，副本因子为-2"><span class="toc-text">例子：一个 topic，单分区，副本因子为 2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#高水位截断数据丢失问题"><span class="toc-text">高水位截断数据丢失问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#高水位机制数据不一致问题"><span class="toc-text">高水位机制数据不一致问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解决高水位的问题"><span class="toc-text">解决高水位的问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Kafka-eagle-监控"><span class="toc-text">5.2 Kafka eagle 监控</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#安装流程"><span class="toc-text">安装流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Flume-和-Kafka-Sink-集成"><span class="toc-text">5.3 Flume 和 Kafka Sink 集成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-Spring-Boot-集成-Kafka"><span class="toc-text">5.4 Spring Boot 集成 Kafka</span></a></li></ol></li></ol></div></div><div class="post-content"><p>kafka 关键概念理解也演示；kafka 安装和部署；kafka 监控。<br><a id="more"></a></p>
<h2 id="1-什么是-kafka？"><a href="#1-什么是-kafka？" class="headerlink" title="1. 什么是 kafka？"></a>1. 什么是 kafka？</h2><h3 id="1-1-Kafka-amp-MQ-场景"><a href="#1-1-Kafka-amp-MQ-场景" class="headerlink" title="1.1 Kafka &amp; MQ 场景"></a>1.1 Kafka &amp; MQ 场景</h3><p>Apache 软件基金会开发的一个开源<strong>流处理平台</strong>，由 Scala 和 Java 编写。是一种高吞吐量的分布式发布订阅消息系统。</p>
<p>MQ 特性：</p>
<ul>
<li>订阅、发布</li>
<li>系统间解耦</li>
<li>异步通信</li>
<li>削峰填谷</li>
</ul>
<p>功能：</p>
<ul>
<li>消息队列 Message Queue</li>
<li>Kafka Streaming 流处理（运行在应用端）</li>
</ul>
<p>例子：用户注册和发送短信。中间可以增加消息队列，用户注册成功后，注册服务器发送一个消息后直接返回成功。</p>
<p><img src="../../images/kafka/异步通信_系统解耦_削峰填谷.png" alt=""></p>
<p><strong>问题：</strong>削峰填谷怎么实现的？大批量数据打入 mq 后，怎么实现平缓消费？背压？</p>
<h3 id="1-2-Kafka-架构刨析"><a href="#1-2-Kafka-架构刨析" class="headerlink" title="1.2 Kafka 架构刨析"></a>1.2 Kafka 架构刨析</h3><h4 id="常见消息队列模式"><a href="#常见消息队列模式" class="headerlink" title="常见消息队列模式"></a>常见消息队列模式</h4><ol>
<li>至多一次：消息确认被消费后，消息服务器主动删除队列中的数据</li>
<li>没有限制：消息可以被多个消费者消费。消息可以被消费多次。</li>
</ol>
<h4 id="Record、Topic、Broker、Leader-、-Fllower-和分区"><a href="#Record、Topic、Broker、Leader-、-Fllower-和分区" class="headerlink" title="Record、Topic、Broker、Leader 、 Fllower 和分区"></a>Record、Topic、Broker、Leader 、 Fllower 和分区</h4><p><strong>Record</strong>：一个 Record 属于一个 Topic</p>
<p><strong>Topic</strong>：每个 topic 都会对应<strong>一组</strong>分区。即一个 topic 可以有多个分区，不同分区的 leader 位于不同的 broker 机器。增打了吞吐量。</p>
<p><strong>Broker</strong>：Topic 的每一个日志的分区都一定会由一个 Broker 担当该分区的 Leader，其他 Broker 担当该分区的 follower。</p>
<p><strong>Leader</strong>：针对分区，指的是分区的 leader，leader 负责分区数据的<strong>读写</strong>操作。例如 分区 0，位与三个 broker，只会有一个 broker 担任分区 0 的 leader。</p>
<p><strong>Follower</strong>： 针对分区，负责同步该分区的数据。Leader 宕机，该分区的其他 Follower 会选取出新的 Leader。</p>
<p><strong>zookeeper</strong>：集群中的 Leader 的<strong>监控</strong>和 Topic <strong>部分元数据</strong>存储在 zookeeper。</p>
<p><img src="../../images/kafka/kafka集群.png" alt=""></p>
<p><strong>数据分发</strong>：生产者生产指定 topic 数据后，如果 record 指定了 key，会使用 hash 函数计算后取模，决定 record 存入哪个分区。hash 函数的特征是<strong>相同的内容返回相同的 hash 值，不同的内容，尽量返回不同的 hash</strong>。使得数据均匀分散在各个分区中；相同的 key 肯定在相同的分区，因为相同的 key 进行 hash 计算肯定相同。</p>
<p><strong>副本因子</strong>：数据一共有多少份。副本因子应该小于 broker 数量，因为同一台机器存放多个副本没有什么意义。</p>
<p><strong>默认持久化时间</strong>：指定 kafka 数据过多久删除，由<code>log.retention.hours=168</code> 配置指定。默认 168 小时即 7 天。</p>
<p><strong>分区</strong>：kafka 只能保证<strong>分区内部有序</strong>，不保证分区之间的消息的顺序。也就是说同一个 topic 如果发送消息的 key 不同，则数据可能分布在不同的分区，这样即使是同一个 topic 的数据也无法保证有序。解决方案是用户自己保证相同的 topic 的消息 key 相同？这样貌似也是有问题的，有些热点 topic 数据可能极大，如果同一个 topic key 相同，这样可能会造成分区数据倾斜，这怎么办呢？</p>
<p>kafka 为什么要分区？</p>
<ul>
<li>打破单机存储的容量，实现海量数据存储</li>
<li>提升 kafka 高并发写入性能</li>
</ul>
<h3 id="1-3-kafka-特性"><a href="#1-3-kafka-特性" class="headerlink" title="1.3 kafka 特性"></a>1.3 kafka 特性</h3><h4 id="顺序写-amp-mmap-针对生产者"><a href="#顺序写-amp-mmap-针对生产者" class="headerlink" title="顺序写&amp;mmap-针对生产者"></a>顺序写&amp;mmap-针对生产者</h4><p>Kafka 的特性之一就是<strong>高吞吐量</strong>，但是 Kafka 的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写数据是会降低性能的，但是 Kafka 即使是普通的服务器，Kafka 也可以轻松支持每秒百万级别的写入请求，超过了大部分的消息中间件。Kafka 会把收到的消息都写入到硬盘中，防止丢失数据，为了优化写入速度，采用了<strong>顺序写入和 MMFile</strong>。</p>
<p>应为硬盘是机械结构，每次读写都会寻址然后写入，其中寻址是一个机械动作，它是最耗时的，所以硬盘最讨厌随机 I/O，最喜欢顺序 I/O，为了提高读写硬盘的速度，Kafka 就是使用的<strong>顺序 I/O</strong>，这样省去了大量的内存开销以及节省了 I/O 寻址的时间，但是单纯的使用顺序写入，Kafka 的写入性能也不可能和内存进行对比，因此 Kafka 的数据并不是实时的写入硬盘中。</p>
<p>Kafka 充分利用了现代操作系统<strong>分页存储</strong>来利用内存，提高 I/O 效率。Memory Mapped Files（mmap）也称内存映射文件，在 64 位操作系统中一般可以表示 20G 的数据文件，它的工作原理是直接利用操作系统的 Page 实现文件到物理内存的直接映射，完成 mmap 映射后，用户对内存的所有操作会被操作系统系统的刷新到磁盘上，极大地降低了 IO 使用率。</p>
<p><img src="../../images/kafka/顺序写_mmap.png" alt=""></p>
<h4 id="Zero-Copy-针对消费者"><a href="#Zero-Copy-针对消费者" class="headerlink" title="Zero Copy-针对消费者"></a>Zero Copy-针对消费者</h4><p>Kafka 服务器在响应客户端读取的时候，底层使用 Zero Copy 技术，无需将磁盘文件拷贝到用户空间，而是直接将数据通过内核空间传递输出，数据并没有抵达用户空间。</p>
<p>传统 IO 操作</p>
<ol>
<li>用户进程调用 read 等系统调用向操作系统发出 IO 请求，请求读取数据到自己的内存缓冲区中，自己进入阻塞状态。</li>
<li>操作系统收到请求后，进一步将 IO 请求发送磁盘</li>
<li>磁盘驱动器收到内核 IO 请求，把数据从磁盘读取到驱动器的缓存中，此时不占用 CPU。当驱动器的缓冲区被读满后，向内核发起<strong>中断信号</strong>，告知自己的缓冲区已满。</li>
<li>内核收到中断，使用 CPU 时间将磁盘驱动器缓存中的数据拷贝到内核缓冲区中。</li>
<li>如果内核缓冲区的数据少于用户申请读的数据，重复步骤 3 和 4，直到内核缓冲区的数据足够多为止</li>
<li>将数据从内核缓冲区拷贝到用户缓冲区，同时从系统调用中返回，完成任务</li>
</ol>
<p><img src="../../images/kafka/常规io.png" alt=""></p>
<p>DMA：<strong>提升 CPU 效率</strong>，但对用户来说没有变化</p>
<p><img src="../../images/kafka/DMA.png" alt=""></p>
<p>零拷贝：<strong>将两次用户态内核态的拷贝优化为一次内核态的拷贝</strong></p>
<p><img src="../../images/kafka/零拷贝.png" alt=""></p>
<h2 id="2-安装-amp-部署"><a href="#2-安装-amp-部署" class="headerlink" title="2. 安装&amp;部署"></a>2. 安装&amp;部署</h2><h3 id="2-1-单机-集群环境搭建"><a href="#2-1-单机-集群环境搭建" class="headerlink" title="2.1 单机/集群环境搭建"></a>2.1 单机/集群环境搭建</h3><ul>
<li>安装 JDK 1.8+，配置 JAVA_HOME</li>
<li>配置主机名和 IP 映射</li>
<li>关闭防火墙&amp;防火墙开机自启动</li>
<li>同步时钟（集群时）</li>
<li>安装&amp;启动 Zookeeper</li>
<li>安装&amp;启动|关闭 Kafka</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 查看 jdk 是否已经安装</span></div><div class="line">rpm -qa| jdk</div><div class="line"><span class="meta">#</span><span class="bash"> 安装 jdk</span></div><div class="line">rpm -ivh jdk...rpm</div><div class="line"><span class="meta">#</span><span class="bash"> 卸载</span></div><div class="line">rpm -e `rpm -qa | grep jdk`</div><div class="line"><span class="meta">#</span><span class="bash"> 查看 jdk</span></div><div class="line">ls /usr/</div><div class="line"><span class="meta">#</span><span class="bash"> 验证 jdk_home 是否配置成功</span></div><div class="line">echo $JAVA_HOME</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 修改主机名</span></div><div class="line">vim /etc/sysconfig/network</div><div class="line">  HOSTNAME=node01</div><div class="line"><span class="meta">#</span><span class="bash"> 配置主机名和IP 映射</span></div><div class="line">vim /etc/hosts</div><div class="line">  192.168.238.66 node01</div><div class="line">  192.168.238.68 node02</div><div class="line">  192.168.238.70 node03</div><div class="line">  192.168.238.72 node04</div><div class="line">ping node01</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 关闭防火墙</span></div><div class="line">service iptables status</div><div class="line">service iptables stop</div><div class="line"><span class="meta">#</span><span class="bash"> 把防火墙服务从开机自启中删除</span></div><div class="line">chkconfig iptables off</div><div class="line">chkconfig --list</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 安装单机 zookeeper</span></div><div class="line"><span class="meta">#</span><span class="bash"> 见 zookeeper 教程</span></div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 安装 kafka</span></div><div class="line">cd /opt</div><div class="line">tar -zxf /root/soft/kafka_2.12-2.3.1.tgz</div><div class="line">vim config/server.properties</div><div class="line"><span class="meta">  #</span><span class="bash"> broker id</span></div><div class="line">  broker.id=0</div><div class="line"><span class="meta">  #</span><span class="bash"> 监听端口号 node01 为主机名称</span></div><div class="line">  listeners=PLAINTEXT://node01:9092</div><div class="line"><span class="meta">  #</span><span class="bash"> 日志地址</span></div><div class="line">  log.dirs=/var/alvin/kafka-logs</div><div class="line"><span class="meta">  #</span><span class="bash"> zookeeper 地址</span></div><div class="line">  zookeeper.connect=node01:2181</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 启动 kafka</span></div><div class="line">./bin/kafka-server-start.sh -daemon config/server.properties</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 创建 topic</span></div><div class="line">./bin/kafka-topics.sh --help</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 报错。Replication factor: 3 larger than available brokers: 1.</span></span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092 --create --topic topic01 --partitions 2 --replication-factor 3</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 正常</span></span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092 --create --topic topic01 --partitions 3 --replication-factor 1</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 创建消费者</span></div><div class="line">./bin/kafka-console-consumer.sh --bootstrap-server node01:9092 --topic topic01 --group group1</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 创建生产者</span></div><div class="line">./bin/kafka-console-producer.sh --broker-list node01:9092 --topic topic01</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 消费组内轮询效果（组内均分效果）。</span></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 再为 group1 创建两个消费者，然后生产数据发现三个消费者轮询消费</span></span></div><div class="line">./bin/kafka-console-consumer.sh --bootstrap-server node01:9092 --topic topic01 --group group1</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 组间广播效果</span></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 创建一个 group2 的消费者</span></span></div><div class="line">./bin/kafka-console-consumer.sh --bootstrap-server node01:9092 --topic topic01 --group group2</div></pre></td></tr></table></figure>
<h3 id="2-2-kafka-集群环境搭建"><a href="#2-2-kafka-集群环境搭建" class="headerlink" title="2.2 kafka 集群环境搭建"></a>2.2 kafka 集群环境搭建</h3><h4 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 时钟同步</span></div><div class="line">yun install ntp -y</div><div class="line">ntpdate ntp[1-7].aliyun.com</div><div class="line">clock -w</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> zookeeper 集群</span></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 1. 配置 server</span></span></div><div class="line">server.1=192.168.238.66:2888:3888</div><div class="line">server.2=192.168.238.68:2888:3888</div><div class="line">server.3=192.168.238.70:2888:3888</div><div class="line">server.4=192.168.238.72:2888:3888</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 2. dataDir=/var/alvin/zookeeper 目录下增加 mypid 文件</span></span></div><div class="line">echo 1 &gt; /var/alvin/zookeeper/mypid</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> kafka 集群</span></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 1. 修改 broker id</span></span></div><div class="line">broker.id=0</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 2. 配置 zookeeper 连接</span></span></div><div class="line">zookeeper.connect=node01:2181,node02:2181,node03:2181</div></pre></td></tr></table></figure>
<h4 id="使用集群"><a href="#使用集群" class="headerlink" title="使用集群"></a>使用集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 创建 topic02</span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --create --topic topic02 --partitions 3 --replication-factor 2</div><div class="line"><span class="meta">#</span><span class="bash"> 查看 topic 列表</span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --list</div><div class="line"><span class="meta">#</span><span class="bash"> 查看 topic 详情</span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092 --describe --topic topic02</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 创建 topic03</span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --create --topic topic03 --partitions 2 --replication-factor 3</div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092 --describe --topic topic03</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 修改 topic03 </span></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 报错，分区数只能增不能减</span></span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --alter --topic topic03 --partitions 1</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 正常</span></span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --alter --topic topic03 --partitions 2</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 删除 topic</span></div><div class="line">./bin/kafka-topics.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --delete --topic topic03</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 订阅 topic01</span></div><div class="line">./bin/kafka-console-consumer.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --topic topic01 --group g1 --property print.key=true --property print.value=true --property key.separator=,</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 发布</span></div><div class="line">./bin/kafka-console-consumer.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --topic topic01 --group g1 --property print.key=true --property print.value=true --property key.separator=,</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 消费者组</span></div><div class="line">./bin/kafka-consumer-groups.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --list</div><div class="line"></div><div class="line">./bin/kafka-consumer-groups.sh --bootstrap-server node01:9092,node02:9092,node03:9092 --describe --group g1</div></pre></td></tr></table></figure>
<p><img src="../../images/kafka/kafka集群_me.png" alt=""></p>
<p>如果消息没有 key，则轮询。有 key 则根据 key hash。</p>
<h2 id="3-Kafka-基础-API"><a href="#3-Kafka-基础-API" class="headerlink" title="3. Kafka 基础 API"></a>3. Kafka 基础 API</h2><h3 id="3-1-topic-的基本操作"><a href="#3-1-topic-的基本操作" class="headerlink" title="3.1 topic 的基本操作"></a>3.1 topic 的基本操作</h3><p>创建、删除、列表、查看详情</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaTopicDml</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</div><div class="line">        <span class="comment">// 1. 创建 KafkaAdminClient</span></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        KafkaAdminClient adminClient = (KafkaAdminClient) KafkaAdminClient.create(props);</div><div class="line"></div><div class="line">        <span class="comment">// 创建 Topic 信息</span></div><div class="line">        CreateTopicsResult createTopicsResult = adminClient.createTopics(Arrays.asList(<span class="keyword">new</span> NewTopic(<span class="string">"topic03"</span>, <span class="number">3</span>, (<span class="keyword">short</span>) <span class="number">3</span>)));</div><div class="line">        createTopicsResult.all().get(); <span class="comment">// 修改为同步创建</span></div><div class="line"></div><div class="line">        <span class="comment">// 删除 Topic</span></div><div class="line"><span class="comment">//        DeleteTopicsResult deleteTopicsResult = adminClient.deleteTopics(Arrays.asList("topic02", "topic03"));</span></div><div class="line"><span class="comment">//        deleteTopicsResult.all().get();</span></div><div class="line"></div><div class="line">        <span class="comment">// 查看 Topic 列表</span></div><div class="line">        ListTopicsResult topicsResult = adminClient.listTopics();</div><div class="line">        Set&lt;String&gt; names = topicsResult.names().get();</div><div class="line">        <span class="keyword">for</span> (String name : names) &#123;</div><div class="line">            System.out.println(name);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 查看 Topic 详细信息</span></div><div class="line">        DescribeTopicsResult dtr = adminClient.describeTopics(Arrays.asList(<span class="string">"topic01"</span>));</div><div class="line">        Map&lt;String, TopicDescription&gt; topicDescMap = dtr.all().get();</div><div class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, TopicDescription&gt; entry : topicDescMap.entrySet()) &#123;</div><div class="line">            System.out.println(entry.getKey() + <span class="string">"\t"</span> + entry.getValue());</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// 关闭 AdminClient</span></div><div class="line">        adminClient.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-2-生产者-消费者代码"><a href="#3-2-生产者-消费者代码" class="headerlink" title="3.2 生产者/消费者代码"></a>3.2 生产者/消费者代码</h3><p>消费者：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerQuickStart</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="comment">// 1. 创建 KafkaConsumer</span></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        <span class="comment">// 消费者肯定属于一个组</span></div><div class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"g1"</span>);</div><div class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div><div class="line"></div><div class="line">        <span class="comment">// 2. 订阅相关的 topics</span></div><div class="line">        consumer.subscribe(Pattern.compile(<span class="string">"^topic.*"</span>));</div><div class="line"></div><div class="line">        <span class="comment">// 遍历消息队列</span></div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</div><div class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;</div><div class="line">                Iterator&lt;ConsumerRecord&lt;String, String&gt;&gt; iterator = records.iterator();</div><div class="line">                <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">                    ConsumerRecord&lt;String, String&gt; record = iterator.next();</div><div class="line">                    System.out.println(record.topic()+<span class="string">"\t"</span>+record.partition()+<span class="string">","</span></div><div class="line">                            +record.offset()+<span class="string">"\t"</span>+record.key()+<span class="string">" "</span>+record.value()+<span class="string">" "</span>+record.timestamp());</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>观察日志输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 启动第一个消费者（三个组全部分配给消费者1）</span></div><div class="line">Setting newly assigned partitions: topic01-2, topic01-1, topic01-0</div><div class="line"><span class="meta">#</span><span class="bash"> 再启动一个消费者</span></div><div class="line">消费者1：Setting newly assigned partitions: topic01-1, topic01-0</div><div class="line">消费者2：Setting newly assigned partitions: topic01-2</div><div class="line"><span class="meta">#</span><span class="bash"> 再启动一个消费者</span></div><div class="line">消费者1：Setting newly assigned partitions: topic01-0</div><div class="line">消费者2：Setting newly assigned partitions: topic01-1</div><div class="line">消费者3：Setting newly assigned partitions: topic01-2</div><div class="line"><span class="meta">#</span><span class="bash"> 再启动一个消费者，g2 组</span></div><div class="line">消费者4：Setting newly assigned partitions: topic01-2, topic01-1, topic01-0</div></pre></td></tr></table></figure>
<p>由上可以看出，同一个组内，每次新增消费者都会<strong>重新分配分区</strong>，因为组内消息消费是均分的。组间对 topic 消费是并行的。</p>
<p>生产者：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerQuickStart</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="comment">// 1. 创建 KafkaProducer</span></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</div><div class="line">            ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"topic01"</span>, <span class="string">"key"</span> + i, <span class="string">"value"</span> + i);</div><div class="line">            <span class="comment">// 发送消息</span></div><div class="line">            producer.send(record);</div><div class="line">        &#125;</div><div class="line">        producer.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>手动指定消费分区和每个分区消费位置</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerQuickStart_2</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="comment">// 1. 创建 KafkaConsumer</span></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        <span class="comment">// 不再使用 kafka 自己的组协调机制</span></div><div class="line"><span class="comment">//        props.put(ConsumerConfig.GROUP_ID_CONFIG, "g2");</span></div><div class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</div><div class="line"></div><div class="line">         <span class="comment">// 2. 订阅相关的 topics，手动指定消费分区，这样将失去组管理特性</span></div><div class="line"><span class="comment">//        consumer.subscribe(Pattern.compile("^topic.*"));</span></div><div class="line">        List&lt;TopicPartition&gt; partitions = Arrays.asList(<span class="keyword">new</span> TopicPartition(<span class="string">"topic01"</span>, <span class="number">0</span>),<span class="keyword">new</span> TopicPartition(<span class="string">"topic01"</span>, <span class="number">1</span>));</div><div class="line">        consumer.assign(partitions);</div><div class="line">        <span class="comment">// 指定消费分区的位置</span></div><div class="line">        <span class="comment">// consumer.seekToBeginning(partitions); // 从头开始消费</span></div><div class="line">        consumer.seek(<span class="keyword">new</span> TopicPartition(<span class="string">"topic01"</span>, <span class="number">0</span>), <span class="number">1</span>); <span class="comment">// 分区 0 从 1 开始取</span></div><div class="line">        consumer.seek(<span class="keyword">new</span> TopicPartition(<span class="string">"topic01"</span>, <span class="number">1</span>), <span class="number">2</span>); <span class="comment">// 分区 1 从 2 开始取</span></div><div class="line"></div><div class="line">        <span class="comment">// 遍历消息队列</span></div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</div><div class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;</div><div class="line">                Iterator&lt;ConsumerRecord&lt;String, String&gt;&gt; iterator = records.iterator();</div><div class="line">                <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">                    ConsumerRecord&lt;String, String&gt; record = iterator.next();</div><div class="line">                    System.out.println(record.topic()+<span class="string">"\t"</span>+record.partition()+<span class="string">","</span></div><div class="line">                            +record.offset()+<span class="string">"\t"</span>+record.key()+<span class="string">" "</span>+record.value()+<span class="string">" "</span>+record.timestamp());</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>注意这样会失去 kafka 组内消费自动协调的功能，相当于每个消费者都是独立的，不会互相影响。</p>
<h3 id="3-4-自定义分区策略"><a href="#3-4-自定义分区策略" class="headerlink" title="3.4 自定义分区策略"></a>3.4 自定义分区策略</h3><h4 id="默认分区策略"><a href="#默认分区策略" class="headerlink" title="默认分区策略"></a>默认分区策略</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">DefaultPartitioner</div><div class="line">* The default partitioning strategy:</div><div class="line">* &lt;ul&gt;</div><div class="line">* &lt;li&gt;If a partition is specified in the record, use it</div><div class="line">* &lt;li&gt;If no partition is specified but a key is present choose a partition based on a hash of the key</div><div class="line">* &lt;li&gt;If no partition or key is present choose a partition in a round-robin fashion</div></pre></td></tr></table></figure>
<h4 id="自定义分区策略"><a href="#自定义分区策略" class="headerlink" title="自定义分区策略"></a>自定义分区策略</h4><p>自定义类实现 Partitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDefinePartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</div><div class="line"></div><div class="line">    AtomicInteger counter = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * 返回分区号</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</div><div class="line">        <span class="comment">// 获取所有分区</span></div><div class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</div><div class="line">        <span class="keyword">int</span> numPartitions = partitions.size();</div><div class="line">        <span class="comment">// 没有key，轮询</span></div><div class="line">        <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">int</span> andIncrement = counter.getAndIncrement();</div><div class="line">            <span class="keyword">return</span> (andIncrement &amp; Integer.MAX_VALUE) % numPartitions;</div><div class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 有 key hash 分发</span></div><div class="line">            <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"close..."</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"configure..."</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>生产者指定分区策略</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerPartitioner</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="comment">// 1. 创建 KafkaProducer</span></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line">        <span class="comment">// 指定自定义分区类</span></div><div class="line">        props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, UserDefinePartitioner.class.getName());</div><div class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">30</span>; i++) &#123;</div><div class="line">            <span class="comment">// 没有 key，轮询</span></div><div class="line">            <span class="comment">// ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;("topic01", "value" + i);</span></div><div class="line">            <span class="comment">// 有 key，hash 分发</span></div><div class="line">            ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"topic01"</span>, <span class="string">"key"</span> + i, <span class="string">"value"</span> + i);</div><div class="line">            <span class="comment">// 指定 partition</span></div><div class="line">            <span class="comment">// ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;("topic01", 0, "key" + i, "value" + i);</span></div><div class="line"></div><div class="line">            <span class="comment">// 发送消息</span></div><div class="line">            producer.send(record);</div><div class="line">        &#125;</div><div class="line">        producer.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-3-消息的序列化"><a href="#3-3-消息的序列化" class="headerlink" title="3.3 消息的序列化"></a>3.3 消息的序列化</h3><p>自己定义序列化器例子。</p>
<p>序列化：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDefineSerializer</span> <span class="keyword">implements</span> <span class="title">Serializer</span>&lt;<span class="title">Object</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map configs, <span class="keyword">boolean</span> isKey)</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"configure..."</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String topic, Object data) &#123;</div><div class="line">        <span class="keyword">return</span> SerializationUtils.serialize((Serializable) data);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"close..."</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>反序列化：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserDefineDeserializer</span> <span class="keyword">implements</span> <span class="title">Deserializer</span> </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map configs, <span class="keyword">boolean</span> isKey)</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"configure...."</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">deserialize</span><span class="params">(String topic, <span class="keyword">byte</span>[] data)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> SerializationUtils.deserialize(data);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"close...."</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="4-Kafka-API-高级特性"><a href="#4-Kafka-API-高级特性" class="headerlink" title="4. Kafka API 高级特性"></a>4. Kafka API 高级特性</h2><h3 id="4-1-消息拦截器"><a href="#4-1-消息拦截器" class="headerlink" title="4.1 消息拦截器"></a>4.1 消息拦截器</h3><p><code>interceptor.classes</code> 配置指定拦截器。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserdefineIntercepter</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span> </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord <span class="title">onSend</span><span class="params">(ProducerRecord record)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ProducerRecord(record.topic(),record.partition(),record.timestamp(),record.key(),record.value()+<span class="string">"--alvin intr"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</div><div class="line">        System.out.println(metadata.toString()+<span class="string">","</span> + exception);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4-2-Offset-偏移量控制"><a href="#4-2-Offset-偏移量控制" class="headerlink" title="4.2 Offset 偏移量控制"></a>4.2 Offset 偏移量控制</h3><p>新消费者组，初始读取位置控制：</p>
<p>auto.offset.reset=latest/earliest/none</p>
<p>Kafka 消费者在消费数据的时候默认会定期的提交消费的偏移量，告诉 broker 我消费到哪里了，这样就可以保证所有的消息至少可以被消费者消费 1 次，用户可以通过以下两个参数配置：</p>
<ul>
<li>enale.atuo.commit=true 默认</li>
<li>auto.commit.interval.ms=5000 默认</li>
</ul>
<p>自动提交间隔问题：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * <span class="doctag">@author</span> alvin</span></div><div class="line"><span class="comment"> * <span class="doctag">@date</span> 2020-07-05 20:13</span></div><div class="line"><span class="comment"> * 新的消费者 g7，从头开始消费。</span></div><div class="line"><span class="comment"> * 在提交 offset 之前关闭程序。</span></div><div class="line"><span class="comment"> * 再启动程序，发现还是可以消费到之前的记录</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerOffest03</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Properties prop = <span class="keyword">new</span> Properties();</div><div class="line">        prop.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        prop.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        prop.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        prop.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"g7"</span>);</div><div class="line">        <span class="comment">// 默认 latest</span></div><div class="line">        prop.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</div><div class="line">        <span class="comment">// 十秒才提交 offset</span></div><div class="line">        prop.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">10000</span>);</div><div class="line">        <span class="comment">// 允许自动提交</span></div><div class="line">        prop.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">true</span>);</div><div class="line"></div><div class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(prop);</div><div class="line"></div><div class="line">        consumer.subscribe(Arrays.asList(<span class="string">"topic01"</span>));</div><div class="line"></div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</div><div class="line">            <span class="keyword">if</span> (records.isEmpty()) <span class="keyword">continue</span>;</div><div class="line">            Iterator&lt;ConsumerRecord&lt;String, String&gt;&gt; iterator = records.iterator();</div><div class="line">            <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">                ConsumerRecord&lt;String, String&gt; record = iterator.next();</div><div class="line">                System.out.println(record.topic()+<span class="string">"\t"</span>+record.partition()+<span class="string">","</span></div><div class="line">                        +record.offset()+<span class="string">"\t"</span>+record.key()+<span class="string">" "</span>+record.value()+<span class="string">" "</span>+record.timestamp());</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>手动提交：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * <span class="doctag">@author</span> alvin</span></div><div class="line"><span class="comment"> * <span class="doctag">@date</span> 2020-07-05 20:13</span></div><div class="line"><span class="comment"> * 关闭自动提交。</span></div><div class="line"><span class="comment"> * 手动提交 offset 必须加一，即提交的是下一次读取的 offset</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerOffest04</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Properties prop = <span class="keyword">new</span> Properties();</div><div class="line">        prop.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        prop.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        prop.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</div><div class="line">        prop.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"g8"</span>);</div><div class="line">        <span class="comment">// 默认 latest</span></div><div class="line">        prop.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</div><div class="line">        <span class="comment">// 允许自动提交</span></div><div class="line">        prop.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>);</div><div class="line"></div><div class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(prop);</div><div class="line"></div><div class="line">        consumer.subscribe(Arrays.asList(<span class="string">"topic01"</span>));</div><div class="line"></div><div class="line">        Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line"></div><div class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</div><div class="line">            <span class="keyword">if</span> (records.isEmpty()) <span class="keyword">continue</span>;</div><div class="line">            Iterator&lt;ConsumerRecord&lt;String, String&gt;&gt; iterator = records.iterator();</div><div class="line">            <span class="keyword">while</span> (iterator.hasNext()) &#123;</div><div class="line">                ConsumerRecord&lt;String, String&gt; record = iterator.next();</div><div class="line">                <span class="comment">// 记录消费分区的偏移量元数据，这里一定要加一，不然每个分区的最后一条数据提交不上去</span></div><div class="line">                offsets.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), <span class="keyword">new</span> OffsetAndMetadata(record.offset()+<span class="number">1</span>));</div><div class="line">                <span class="comment">// 提交消费者偏移量</span></div><div class="line">                consumer.commitAsync(offsets, <span class="keyword">new</span> OffsetCommitCallback() &#123;</div><div class="line">                    <span class="meta">@Override</span></div><div class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onComplete</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception)</span> </span>&#123;</div><div class="line">                        System.out.println(<span class="string">"offsets:"</span> + offsets + <span class="string">"\texception:"</span> + exception);</div><div class="line">                    &#125;</div><div class="line">                &#125;);</div><div class="line">                System.out.println(record.topic()+<span class="string">"\t"</span>+record.partition()+<span class="string">","</span></div><div class="line">                        +record.offset()+<span class="string">"\t"</span>+record.key()+<span class="string">" "</span>+record.value()+<span class="string">" "</span>+record.timestamp());</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4-3-Acks-amp-Retries"><a href="#4-3-Acks-amp-Retries" class="headerlink" title="4.3 Acks &amp; Retries"></a>4.3 Acks &amp; Retries</h3><ul>
<li><p>生产者发送消息要求 Broker 在规定时间（<strong>request.timeout.ms</strong>）内应答  Ack</p>
</li>
<li><p>什么时候应答可由 Ack 配置</p>
<ul>
<li>acks=1，Leader 将 Record 记录到本地日志后，不等待 Follower 的响应，立即返回。如果 Leader 确认记录后，Follower 复制记录之前宕机，则记录将丢失。</li>
<li>acks=0，生产者不会等待服务器的任何确认，自己把记录添加到套接字缓冲区中就视为已发送。这种情况下不能保证服务器已经收到记录。</li>
<li>acks=all，Leader 等所有 Follower 确认后再给生产者回复确认。这是最有力的保证。和 acks=-1 相同。</li>
</ul>
</li>
<li>生产者没有收到 Broker Ack 应答或应答超时，生产者可以设置重试次数（<strong>retries</strong>)。</li>
</ul>
<p>三个配置的默认值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 请求超时时间，broker 在该时间内没有应答这重发</div><div class="line">request.timeout.ms=30000</div><div class="line"># 重发次数</div><div class="line">retries=214748647</div><div class="line"># 只需要 leadder 收到消息接口，不需要所有 follower 同步完成</div><div class="line">acks=1</div></pre></td></tr></table></figure>
<p>注意：<strong>retries 会导致数据重复。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerAcks</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Properties prop = <span class="keyword">new</span> Properties();</div><div class="line">        prop.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        prop.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line">        prop.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line"></div><div class="line">        <span class="comment">// Follower 同步完成后，Leader 应答</span></div><div class="line">        prop.put(ProducerConfig.ACKS_CONFIG, <span class="string">"all"</span>);</div><div class="line">        <span class="comment">// 超时时间设置为 1ms（模拟肯定超时场景）</span></div><div class="line">        prop.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">1</span>);</div><div class="line">        <span class="comment">// 重试 3 次，不包含初始发送那次</span></div><div class="line">        prop.put(ProducerConfig.RETRIES_CONFIG, <span class="number">3</span>);</div><div class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(prop);</div><div class="line"></div><div class="line">        producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"topic01"</span>,<span class="string">"ackskey"</span>, <span class="string">"acksvalue"</span>));</div><div class="line">        producer.flush();</div><div class="line">        producer.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>消费后，发现数据重复。</p>
<h3 id="4-3-幂等性"><a href="#4-3-幂等性" class="headerlink" title="4.3 幂等性"></a>4.3 幂等性</h3><p>HTTP/1.1 中对幂等性的定义：一次和多次请求某一个资源对于资源本身也应该具有同样的结果（网络超时等问题除外）。也就是说，其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。</p>
<p>Methods can also have the property of “idempotence” in that(aside from error or expiration issues) the side-effects of N-&gt;0 indentical requests is the same as for a single request.</p>
<p>Kafka 在 0.11.0.0 版本增加幂等性支持。幂等是针对生产者角度的特性。保证生产者发送的消息<strong>不会丢失(retries)也不会重复</strong>。</p>
<p>实现幂等的关键就是服务端可以区分请求是否重复，过滤掉重复请求：</p>
<ul>
<li>请求中增加唯一标识，例如支付请求中，订单号就是唯一标识。</li>
<li>记录已经处理过的请求，用于和新请求的唯一标识对比，从而判断请求是否为重复请求。如果重复，则拒绝掉。</li>
</ul>
<p>幂等又称为 exactly one。在初始化期间，kafka 会给生产者生成一个唯一的 ID 称为 Producer ID 或 PID。</p>
<p>PID 和序列号与消息捆绑在一起，然后发送给 Broker。</p>
<p>序列号从零开始并且单调递增，因此，仅仅当消息的序列号比该 PID/TopicPartition 对中最后提交的消息的系列号大 1 时，Broker 才会接收该消息。如果不是这种情况，则 Broker 认定是生产者重发该消息。</p>
<p>开启幂等：enable.idempotence=true 默认为 false</p>
<p>注意：在使用幂等的时候，要求必须开启 retries=true 和 acks=all，并且 max.in.flight.requests.per.connection 小于等于 5。</p>
<p><img src="../../images/kafka/幂等.png" alt=""></p>
<p>生产者新增配置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 开启幂等性，默认为 false</span></div><div class="line">prop.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="keyword">true</span>);</div><div class="line"><span class="comment">// 一个连接发送未确认请求阻塞前的最大数量。</span></div><div class="line"><span class="comment">// 幂等性要求：必须小于等于 5，建议为 1。如果大于 1，并且设置了重发，就不能保证写入顺序了。</span></div><div class="line">prop.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="number">1</span>);</div></pre></td></tr></table></figure>
<h3 id="4-4-事务控制"><a href="#4-4-事务控制" class="headerlink" title="4.4 事务控制"></a>4.4 事务控制</h3><p>Kafka 的幂等性，只能保证一条记录在<strong>分区发送的原子性</strong>，但是如果要保证多条记录（多个分区）之间的原子性，这个时候就需要开启 Kafka 的事务了。</p>
<p>Kafka 在 0.11.0.0 版本增加幂等性支持的同时也加入事务的支持。</p>
<p>Kafka 有两种事务：</p>
<ol>
<li>生产者 only 事务</li>
<li>消费者 &amp; 生产之事务</li>
</ol>
<p>消费者消费的消息的级别是 read_uncommited 数据，这有可能读取到事务失败的数据（<strong>脏读</strong>），所以在开启了生产者事务之后，需要用户设置消费者的事务隔离级别(<strong>isolation.level=read_committed</strong>)，该配置默认为 read_uncommited。</p>
<p>开启生产者事务，只需要指定 <strong>transactional.id</strong> 属性即可，一旦开启事务，默认生产者就已经开启了幂等性。transactional.id 的取值必须是唯一的，同一时刻只能有一个 transactional.id 存在，其他的将会被关闭。</p>
<h4 id="生产者-only"><a href="#生产者-only" class="headerlink" title="生产者 only"></a>生产者 only</h4><p>生产者：</p>
<ul>
<li><p>transactional.id</p>
</li>
<li><p>enable.idempotence</p>
</li>
<li><p>acks</p>
</li>
<li><p>request.timeout.ms</p>
</li>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">producer.initTransactions();</div><div class="line">producer.beginTransaction();</div><div class="line">producer.commitTransaction();</div><div class="line">producer.abortTransaction();</div></pre></td></tr></table></figure>
</li>
</ul>
<p>消费者：</p>
<ul>
<li>isolation.level</li>
</ul>
<p>生产者示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerTransactionProducerOnly</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line"></div><div class="line">        KafkaProducer&lt;String, String&gt; producer = buildKafkaProducer();</div><div class="line">        <span class="comment">// 1. 初始化事务</span></div><div class="line">        producer.initTransactions();</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="comment">// 2. 开启事务</span></div><div class="line">            producer.beginTransaction();</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</div><div class="line"><span class="comment">//                if (i == 8) &#123;</span></div><div class="line"><span class="comment">//                    int j = 10/0;</span></div><div class="line"><span class="comment">//                &#125;</span></div><div class="line">                ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"topic01"</span>, <span class="string">"transaction"</span> + i, <span class="string">"right data!!!"</span> + i);</div><div class="line">                <span class="comment">// 发送消息</span></div><div class="line">                producer.send(record);</div><div class="line">                producer.flush();</div><div class="line">            &#125;</div><div class="line">            <span class="comment">// 3. 提交事务</span></div><div class="line">            producer.commitTransaction();</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            System.out.println(<span class="string">"出现错误了~"</span> + e.getMessage());</div><div class="line">            <span class="comment">// 4. 终止事务</span></div><div class="line">            producer.abortTransaction();</div><div class="line">        &#125;</div><div class="line">        producer.close();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> KafkaProducer&lt;String, String&gt; <span class="title">buildKafkaProducer</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">// 1. 创建 KafkaProducer</span></div><div class="line">        Properties props = <span class="keyword">new</span> Properties();</div><div class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"node01:9092,node02:9092,node03:9092"</span>);</div><div class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</div><div class="line"></div><div class="line">        <span class="comment">// 必须配置事务 ID。必须是唯一的</span></div><div class="line">        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">"transaction-id"</span>+ UUID.randomUUID().toString());</div><div class="line">        <span class="comment">// 配置 Kafka 批处理大小</span></div><div class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">1024</span>);</div><div class="line">        <span class="comment">// 如果 batch 中数据不足 1024 大小，等待 5ms</span></div><div class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">5</span>);</div><div class="line">        <span class="comment">// 配置 Kafka 重试机制和幂等性</span></div><div class="line">        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="keyword">true</span>);</div><div class="line">        props.put(ProducerConfig.ACKS_CONFIG, <span class="string">"all"</span>);</div><div class="line">        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, <span class="number">20000</span>);</div><div class="line"></div><div class="line">        <span class="keyword">return</span> <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>消费者示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 设置消费者的消费事务的隔离级别 read_committed</span></div><div class="line">props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, <span class="string">"read_committed"</span>);</div><div class="line"><span class="comment">// props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, "read_uncommitted");</span></div></pre></td></tr></table></figure>
<h4 id="生产者消费者事务"><a href="#生产者消费者事务" class="headerlink" title="生产者消费者事务"></a>生产者消费者事务</h4><p>消费 topic01 数据发送到 topic 02。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line"></div><div class="line">    KafkaProducer&lt;String, String&gt; producer = buildKafkaProducer();</div><div class="line">    KafkaConsumer&lt;String, String&gt; consumer = buildKafkaConsumer();</div><div class="line">    <span class="comment">// 1. 初始化事务</span></div><div class="line">    producer.initTransactions();</div><div class="line"></div><div class="line">    consumer.subscribe(Arrays.asList(<span class="string">"topic01"</span>));</div><div class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</div><div class="line">        ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</div><div class="line">        <span class="keyword">if</span> (!consumerRecords.isEmpty()) &#123;</div><div class="line">            Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class="keyword">new</span> HashMap&lt;&gt;();</div><div class="line">            Iterator&lt;ConsumerRecord&lt;String, String&gt;&gt; recordIterator = consumerRecords.iterator();</div><div class="line">            <span class="comment">// 开启事务</span></div><div class="line">            producer.beginTransaction();</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                <span class="comment">// 迭代数据，进行业务处理</span></div><div class="line">                <span class="keyword">while</span> (recordIterator.hasNext()) &#123;</div><div class="line">                    ConsumerRecord&lt;String, String&gt; consumerRecord = recordIterator.next();</div><div class="line">                    <span class="comment">// 存储元数据</span></div><div class="line">                    offsets.put(<span class="keyword">new</span> TopicPartition(consumerRecord.topic(),consumerRecord.partition()),</div><div class="line">                            <span class="keyword">new</span> OffsetAndMetadata(consumerRecord.offset() + <span class="number">1</span>));</div><div class="line">                    producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string">"topic02"</span>, consumerRecord.key(),</div><div class="line">                            consumerRecord.value() + <span class="string">" alvin..."</span>));</div><div class="line">                &#125;</div><div class="line">                <span class="comment">// 提交事务</span></div><div class="line">                producer.sendOffsetsToTransaction(offsets, <span class="string">"g1"</span>); <span class="comment">// 提交消费者的偏移量</span></div><div class="line">                producer.commitTransaction();</div><div class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                System.out.println(<span class="string">"错误了~"</span>  + e.getMessage());</div><div class="line">                <span class="comment">// 终止事务</span></div><div class="line">                producer.abortTransaction();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>问题：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 必须关闭消费者端的 offset 自动提交</span></div><div class="line">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="keyword">false</span>); <span class="comment">// 为啥必须关闭?</span></div></pre></td></tr></table></figure>
<h2 id="5-Kafka-架构进阶"><a href="#5-Kafka-架构进阶" class="headerlink" title="5. Kafka 架构进阶"></a>5. Kafka 架构进阶</h2><h3 id="5-1-Kafka-副本同步机制"><a href="#5-1-Kafka-副本同步机制" class="headerlink" title="5.1 Kafka 副本同步机制"></a>5.1 Kafka 副本同步机制</h3><p>Kafka 的 Topic 被分为多个分区，分区是按照 Segments 存储文件块的。分区日志是存储在磁盘上的日志序列，Kafka 可以保证分区里的事件是有序的。其中 Leader 负责对应分区的读写，Follower 负责同步分区的数据。0.11 版本之前，Kafka 使用 highwatermarker 机制保证数据的同步，但是基于 highwatermarker 的同步数据可能会导致数据的不一致或者是乱序。</p>
<h4 id="关键概念理解"><a href="#关键概念理解" class="headerlink" title="关键概念理解"></a>关键概念理解</h4><p><strong>LEO</strong>：log end offset，标识<strong>每个分区</strong>中下一个写入位置，分区的每个副本都有自己的 LEO。</p>
<p><strong>HW</strong>：high watermarker 称为高水位线。所有 HW 之前的数据都可以理解为是<strong>已经备份</strong>的，当所有节点都备份成功，Leader 会更新水位线。所有副本都有自己的 LEO 和 HW。</p>
<p><strong>ISR</strong>：In-sync-replicas，kafka 的 leader 会维护一份<strong>处于同步的副本集合</strong>，如果在 <code>replica.lag.time.max.ms</code> 时间内，系统没有发送 fetch 请求，或者已经发送请求但是在该期限内没有赶上 leader 的数据就会被剔除 ISR 列表。0.9.0 版本剔除了 <code>replica.lag.max.messages</code> 消息个数限定，因为这个会导致其他的 broker 节点频繁的加入和退出 ISR。</p>
<p><strong>Leader</strong>：Leader 副本，响应 clients 端的读写请求。</p>
<p><strong>Follower</strong>：Follower 副本，被动的备份 leader 副本中 数据，不能响应读写。</p>
<p><strong>所有的副本</strong>（leader、follower）都有 LEO 和 HW 值。</p>
<h4 id="follower-副本更新-LEO-时机"><a href="#follower-副本更新-LEO-时机" class="headerlink" title="follower 副本更新 LEO 时机"></a>follower 副本更新 LEO 时机</h4><p>Kafka 有两套 follower 副本 LEO：1. 一套 LEO 保存在 follower 副本所在的 broker 的副本管理机中；2. 另一套 LEO 保存在 leader 副本所在的 broker 的副本管理机中。<strong>即 leader 副本机器上保存了所有 follower 副本的 LEO。</strong></p>
<p>第一套帮助 follower 副本更新其 HW 值；第二套帮助 leader 部分更新其 HW 值。</p>
<ul>
<li>follower 端 follower 副本的 LEO 何时更新？</li>
</ul>
<p>follower 发送 FETCH 请求后，leader 将数据返回给 follower，此时 follower 开始向底层 log 写数据，从而自动的更新 LEO 值。</p>
<ul>
<li>leader 端 follower 副本的 LEO 何时更新？</li>
</ul>
<p>leader 端 follower 副本的 LEO 更新发生在 leader 处理 follower FETCH 请求时。一旦 leader 收到 follower 发送的 FETCH 请求，它首先会从自己的 log 中读取相应的数据，但是在给 follower 返回数据之前它先去更新 follower 的 LEO。</p>
<h4 id="follower-副本更新-HW-时机"><a href="#follower-副本更新-HW-时机" class="headerlink" title="follower 副本更新 HW 时机"></a>follower 副本更新 HW 时机</h4><p>发生在 follower 更新 LEO 之后。HW = min(follower LEO, leader HW)。由此可见 follower 的 HW 始终小于 leader 的 HW。</p>
<h4 id="leader-副本更新-LEO-时机"><a href="#leader-副本更新-LEO-时机" class="headerlink" title="leader 副本更新 LEO 时机"></a>leader 副本更新 LEO 时机</h4><p>和follower更新LEO道理相同，leader写log时就会自动地更新它自己的LEO值。</p>
<h4 id="leader-副本更新-HW-时机"><a href="#leader-副本更新-HW-时机" class="headerlink" title="leader 副本更新 HW 时机"></a>leader 副本更新 HW 时机</h4><p>这个值直接影响分区数据对于 consumer 的可见性。</p>
<ul>
<li>副本成为 leader 副本时</li>
<li>broker 出现崩溃导致副本被剔除 ISR时</li>
<li>producer 向 leader 副本写入消息时：写入消息会更新 leader 的 LEO，所以有必要再查看下 HW 值是否也需要修改</li>
<li>leader 处理 follower FETCH 请求时：先从底层的 log 读取数据，然后尝试更新分区的 HW 值。选出副本中最小的 LEO 作为 HW 值。候选副本有两个条件：<ul>
<li>处于 ISR 中</li>
<li>副本 LEO 落后于 leader LEO 的时长不大于 replica.lag.time.max.ms 参数值（默认 10 s）</li>
</ul>
</li>
</ul>
<h4 id="例子：一个-topic，单分区，副本因子为-2"><a href="#例子：一个-topic，单分区，副本因子为-2" class="headerlink" title="例子：一个 topic，单分区，副本因子为 2"></a>例子：一个 topic，单分区，副本因子为 2</h4><p><img src="../../images/kafka/hw副本机制.png" alt=""></p>
<ul>
<li>producer 发送一条消息 leader 端处理<ul>
<li>把消息写入底层 log（同时更新了 leader 的 LEO = 1）</li>
<li>尝试更新 leader HW。leader LEO 和 follower LEO 最小值为 0，不更新分区 HW</li>
</ul>
</li>
<li>follower 发送 fetch 请求，leader 端处理<ul>
<li>读取底层 log 数据</li>
<li>更新 follower LEO = 0（思考为什么是 0 ？）</li>
<li>尝试更新分区的 HW = min(leader LEO, follower LEO) = 0</li>
<li>把数据和当前分区 HW 值（依然是 0）发送给 follower 副本</li>
</ul>
</li>
<li>follower 收到 fetch response 后处理<ul>
<li>写入本地 log（同时更新 follower LEO = 1）</li>
<li>尝试更新 follower HW = min(follower LEO, leader HW) = 0</li>
</ul>
</li>
</ul>
<p>此时第一轮 fetch RPC 结束，发现 leader 和 follower 都已经在 log 中保存了这条消息，但是分区 HW 值还没更新</p>
<ul>
<li>follower 再次发送 fetch 请求，leader 端处理<ul>
<li>读取底层 log</li>
<li>更新 follower LEO = 1（思考这次为什么是 1 了？）</li>
<li>尝试更新分区 HW， HW = min(leader LEO, follower LEO) = 1</li>
<li>把数据（实际上没数据）和当前分区 HW 值（已更新为 1）发送给 follower 副本</li>
</ul>
</li>
<li>follower 收到 fetch response 后处理<ul>
<li>写入本地 log（这里每东西可写）</li>
<li>尝试更新 follower HW = min(follower LEO, leader HW) = 1</li>
</ul>
</li>
</ul>
<h4 id="高水位截断数据丢失问题"><a href="#高水位截断数据丢失问题" class="headerlink" title="高水位截断数据丢失问题"></a>高水位截断数据丢失问题</h4><p><img src="../../images/kafka/高水位截断_数据丢失问题.png" alt=""></p>
<p>A 还没来得及同步 B 的水位线，A 宕机；</p>
<p>A 启动起来，截断 A 水位线之后的数据，尝试同步 leader B 数据</p>
<p>B 突然宕机，A 成为新的 leader，数据 m2 永久丢失。</p>
<h4 id="高水位机制数据不一致问题"><a href="#高水位机制数据不一致问题" class="headerlink" title="高水位机制数据不一致问题"></a>高水位机制数据不一致问题</h4><p><img src="../../images/kafka/高水位机制_数据不一致问题.png" alt=""></p>
<h4 id="解决高水位的问题"><a href="#解决高水位的问题" class="headerlink" title="解决高水位的问题"></a>解决高水位的问题</h4><p>造成上面两个问题的根本原因在于 HW 值被用于衡量副本备份的成功与否以及在出现宕机时作为日志截断的依据，但 HW 值的更新是异步延迟的，特别是需要额外的 FETCH 请求处理流程才能更新，故中间发生的任何崩溃都可能导致 HW 值的过期。</p>
<p>kafka 0.11 之后版本引入了 leader epoch 来解决这个问题，不再使用 HW 作为数据截断的依据。</p>
<p>任意一个 leader 都持有一个 leader epoch，该 leader epoch 是一个由 controller 管理的 32 位数字，存储在 zookeeper 的分区状态信息中，并作为 leaderAndIsrRequest 的一部分传递给每个新的 leader。</p>
<p>所谓 leader epoch 实际上是一对值：（epoch, offset），epoch 表示 leader 的版本号，从 0 开始，每次 leader 变更时 epoch 加一，offset 则对应于该 epoch 版本的 leader 写入第一条消息的 offset。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">(0,0)</div><div class="line">(1,120)</div><div class="line"><span class="meta">#</span><span class="bash"> 第一个 leader 从位移 0 开始写入消息，共写了 120 条[0,199]</span></div><div class="line"><span class="meta">#</span><span class="bash"> 第二个 leader 从位移 120 开始写入消息</span></div></pre></td></tr></table></figure>
<p>leader broker 中会保存这样一份缓存，这份缓存会定期地写入到一个 checkpoint 文件中。</p>
<p>每当 leader 写底层 log 时，它会尝试更新整个缓存，如果这个 leader 是首次写消息，则会在缓存中增加一个条目；否则不做更新。</p>
<p>每次副本重新成为 leader 时会查询这个缓存，获取出对应的 leader 版本的位移，这样就不会发生数据不一致和丢失的情况。</p>
<p>leader 接收 producer 请求数据后使用 leader epoch 标记每个 message，然后该 leader epoch 编号将通过复制协议传播，并用于替换 HW 标记，作为消息截断的参考点。</p>
<p><img src="../../images/kafka/leader_epoch机制.png" alt=""></p>
<p>改进消息格式，以便每个消息集都带有一个 4 字节的 leader epoch 号。在每个日志目录中，会创建一个新的 leader epoch sequence 文件，在其中存储 leader epoch 的序列和在该 epoch 中生成的消息的 start offset。它也缓存在每个副本中，也缓存在内存中。</p>
<ul>
<li>follower 变成 leader</li>
</ul>
<p>先将新的 leader epoch 和副本的 LEO 添加到 leader epoch sequence 序列文件的末尾并刷新数据，给 leader 产生的每个新消息集都带有新的 leader epoch 标记。</p>
<ul>
<li>leader 变成 follower</li>
</ul>
<p>如果需要从本地的 leader epoch sequence 加载数据，将数据存储在内存中，给相应的分区的 leader 发送 epoch 请求，该请求包含最新的 epochId,startOffset 信息，leader 接收到信息以后返回该 epochId 所对应的 lastOffset 信息。该信息可能是最新 epochId 的 startoffset 或者是当前 epochId 的 LEO 信息。</p>
<p>说明：</p>
<p>解决数据丢失问题：</p>
<p><img src="../../images/kafka//epoch处理数据丢失问题.png" alt=""></p>
<p>解决数据不一致问题：</p>
<p><img src="../../images/kafka/epoche解决数据不一致问题.png" alt=""></p>
<h3 id="5-2-Kafka-eagle-监控"><a href="#5-2-Kafka-eagle-监控" class="headerlink" title="5.2 Kafka eagle 监控"></a>5.2 Kafka eagle 监控</h3><p>kafka eagle 是一个 kafka 监控平台。相比 kafka tools，kafka eagle 多了一个报表统计、聚合已经提醒等功能。</p>
<p>官网地址：<a href="http://download.kafka-eagle.org/" target="_blank" rel="external">http://download.kafka-eagle.org/</a></p>
<h4 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 下载软件</span></div><div class="line">http://download.kafka-eagle.org/</div><div class="line"><span class="meta">#</span><span class="bash"> 安装软件</span></div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 解压</span></span></div><div class="line">tar -zxvf kafka-eagle-bin-2.0.0.tar.gz</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 移动到安装目录</span></span></div><div class="line">mv kafka-eagle-bin-2.0.0 /opt/kafka-eagle</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 解压 web 包</span></span></div><div class="line">tar -zxvf kafka-eagle-web-2.0.0-bin.tar.gz</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置环境变量</span></span></div><div class="line">vim /etc/profile</div><div class="line">  export KE_HOME=/opt/kafka-eagle</div><div class="line">  export PATH=$PATH:$KE_HOME/bin</div><div class="line">source /etc/profile</div><div class="line">echo $KE_HOME</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 修改 kafka eagle 配置</span></div><div class="line">vim conf/system-config.properties</div><div class="line">  kafka.eagle.zk.cluster.alias=cluster1</div><div class="line">  cluster1.zk.list=node01:2181,node02:2181,node03:2181</div><div class="line">  cluster1.kafka.eagle.offset.storage=kafka</div><div class="line">  kafka.eagle.driver=org.sqlite.JDBC</div><div class="line"><span class="meta">  #</span><span class="bash"> 这里注意 sqllite db 文件的路径</span></div><div class="line">  kafka.eagle.url=jdbc:sqlite:/opt/kafka-eagle/db/ke.db</div><div class="line">  kafka.eagle.username=root</div><div class="line">  kafka.eagle.password=123456</div><div class="line">  </div><div class="line"><span class="meta">#</span><span class="bash"> 修改 kafka 配置</span></div><div class="line">cd kafka_2.12-2.3.1/</div><div class="line">vim bin/kafka-server-start.sh</div><div class="line">    if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then</div><div class="line">        export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"</div><div class="line">        export JMX_PORT="7788"</div><div class="line">    fi</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 重启 kafka 服务</span></span></div><div class="line">jps</div><div class="line">kill -9 11816</div><div class="line">./bin/kafka-server-start.sh -daemon config/server.properties</div><div class="line"></div><div class="line"><span class="meta">#</span><span class="bash"> 启动 kafka eagle</span></div><div class="line">chmod +x ke.sh</div><div class="line">ke.sh start</div></pre></td></tr></table></figure>
<p>这是一个 kafka 的监控系统。感觉实现不是很难，就是连接 kafka 做一些聚合和操作，但是别人却做出来了，而自己只会找轮子，获取这就是差别吧。</p>
<h3 id="5-3-Flume-和-Kafka-Sink-集成"><a href="#5-3-Flume-和-Kafka-Sink-集成" class="headerlink" title="5.3 Flume 和 Kafka Sink 集成"></a>5.3 Flume 和 Kafka Sink 集成</h3><h3 id="5-4-Spring-Boot-集成-Kafka"><a href="#5-4-Spring-Boot-集成-Kafka" class="headerlink" title="5.4 Spring Boot 集成 Kafka"></a>5.4 Spring Boot 集成 Kafka</h3></div><div class="tags"><a href="/tags/kafka/">kafka</a></div><div class="post-nav"><a class="next" href="/2020-07-01-web/C1.html"></a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/IO/">IO</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/JVM/">JVM</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/LVS/">LVS</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx/">Nginx</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring-Cloud/">Spring Cloud</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SpringCloud/">SpringCloud</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Srping-Boot/">Srping Boot</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ZooKeeper/">ZooKeeper</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/css/">css</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/vue/">vue</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/加解密技术/">加解密技术</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/吉他/">吉他</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/多线程/">多线程</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/心情/">心情</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/消息队列/">消息队列</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/疯狂-Java-讲义/">疯狂 Java 讲义</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络/">网络</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/计划/">计划</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/设计模式/">设计模式</a><span class="category-list-count">4</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/网络/" style="font-size: 15px;">网络</a> <a href="/tags/计划/" style="font-size: 15px;">计划</a> <a href="/tags/PGP/" style="font-size: 15px;">PGP</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Samba/" style="font-size: 15px;">Samba</a> <a href="/tags/Oracle/" style="font-size: 15px;">Oracle</a> <a href="/tags/NIO/" style="font-size: 15px;">NIO</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/MQTT/" style="font-size: 15px;">MQTT</a> <a href="/tags/Redis/" style="font-size: 15px;">Redis</a> <a href="/tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="/tags/Blog/" style="font-size: 15px;">Blog</a> <a href="/tags/IO/" style="font-size: 15px;">IO</a> <a href="/tags/SFTP/" style="font-size: 15px;">SFTP</a> <a href="/tags/LVS/" style="font-size: 15px;">LVS</a> <a href="/tags/心情/" style="font-size: 15px;">心情</a> <a href="/tags/SpringCloud/" style="font-size: 15px;">SpringCloud</a> <a href="/tags/Srping-Boot/" style="font-size: 15px;">Srping Boot</a> <a href="/tags/Eureka/" style="font-size: 15px;">Eureka</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/css/" style="font-size: 15px;">css</a> <a href="/tags/vue/" style="font-size: 15px;">vue</a> <a href="/tags/多线程/" style="font-size: 15px;">多线程</a> <a href="/tags/疯狂-Java-讲义/" style="font-size: 15px;">疯狂 Java 讲义</a> <a href="/tags/吉他/" style="font-size: 15px;">吉他</a> <a href="/tags/Observer/" style="font-size: 15px;">Observer</a> <a href="/tags/ZooKeeper/" style="font-size: 15px;">ZooKeeper</a> <a href="/tags/Proxy/" style="font-size: 15px;">Proxy</a> <a href="/tags/设计模式/" style="font-size: 15px;">设计模式</a> <a href="/tags/Singleton/" style="font-size: 15px;">Singleton</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://blog.jamespan.me/" title="小鶸の道场" target="_blank">小鶸の道场</a><ul></ul><a href="https://www.haomwei.com/" title="屠城" target="_blank">屠城</a><ul></ul><a href="http://www.ruanyifeng.com/home.html" title="阮一峰" target="_blank">阮一峰</a><ul></ul><a href="https://www.cnblogs.com/jingmoxukong/" title="静默虚空" target="_blank">静默虚空</a><ul></ul><a href="https://blog.hushhw.cn/" title="hushhw" target="_blank">hushhw</a><ul></ul><a href="https://hasaik.com/" title="hasaik" target="_blank">hasaik</a><ul></ul><a href="https://www.imalan.cn/" title="三无计划" target="_blank">三无计划</a><ul></ul><a href="https://i-meto.com/" title="meto" target="_blank">meto</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">悟空.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>